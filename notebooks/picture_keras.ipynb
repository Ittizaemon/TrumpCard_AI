{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fce84c5-cd1f-4630-a394-05f1fb39a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 05:43:34.435934: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-22 05:43:34.463347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 05:43:34.463362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 05:43:34.464019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 05:43:34.468910: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 05:43:35.185149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-22 05:43:35.693726: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:35.710339: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:35.710400: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 2500\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "#データ準備\n",
    "path = \"train-data/\"\n",
    "\n",
    "files = glob.glob(path + \"train/*.jpg\")   #.jpgのパスを取得\n",
    "files = sorted(files)\n",
    "df_label = pd.read_csv(path + \"train.csv\")\n",
    "\n",
    "# file_pathとcsv行を抽出する\n",
    "def inexclusion(num: int):\n",
    "  return files[:num], df_label.head(num)\n",
    "\n",
    "files, df_label = inexclusion(2500)\n",
    "\n",
    "file_list = []\n",
    "for file in files:\n",
    "  file = cv2.imread(file)\n",
    "  file_list.append(file)\n",
    "\n",
    "#要素数の確認\n",
    "print(len(file_list),len(df_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c40a27-2b08-466c-987f-7c02fd659e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#画素値を正規化\n",
    "file_list = [file.astype(float)/255 for file in file_list]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(file_list, df_label, test_size=0.2)\n",
    "\n",
    "# train_y, valid_y をダミー変数化\n",
    "train_y = to_categorical(train_y[\"gender_status\"])\n",
    "valid_y = to_categorical(valid_y[\"gender_status\"])\n",
    "\n",
    "# リスト型を配列型に\n",
    "train_x = np.array(train_x)\n",
    "valid_x = np.array(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b175186c-e8d1-4880-ab87-6decf46858bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 05:43:39.322695: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:39.322838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:39.322865: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:39.419842: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:39.419903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:39.419909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-22 05:43:39.419938: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-22 05:43:39.419955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5606 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 05:43:42.087243: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-22 05:43:42.443138: I external/local_xla/xla/service/service.cc:168] XLA service 0x1512abe62750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-22 05:43:42.443164: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2023-12-22 05:43:42.447661: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1703223822.525871   14603 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 6s 17ms/step - loss: 7.0229 - accuracy: 0.2855 - val_loss: 1.6249 - val_accuracy: 0.3020\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.6236 - accuracy: 0.2855 - val_loss: 1.6232 - val_accuracy: 0.3020\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6238 - accuracy: 0.2840 - val_loss: 1.6248 - val_accuracy: 0.2720\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6248 - accuracy: 0.2850 - val_loss: 1.6268 - val_accuracy: 0.3020\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 1.6218 - accuracy: 0.2970 - val_loss: 1.6243 - val_accuracy: 0.3020\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6238 - accuracy: 0.2955 - val_loss: 1.6205 - val_accuracy: 0.2720\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6238 - accuracy: 0.2915 - val_loss: 1.6227 - val_accuracy: 0.3020\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6239 - accuracy: 0.2905 - val_loss: 1.6237 - val_accuracy: 0.3020\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6221 - accuracy: 0.2850 - val_loss: 1.6250 - val_accuracy: 0.2720\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6229 - accuracy: 0.2910 - val_loss: 1.6243 - val_accuracy: 0.2720\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6221 - accuracy: 0.2970 - val_loss: 1.6241 - val_accuracy: 0.2720\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6228 - accuracy: 0.2870 - val_loss: 1.6287 - val_accuracy: 0.3020\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6224 - accuracy: 0.3010 - val_loss: 1.6313 - val_accuracy: 0.3020\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6215 - accuracy: 0.3040 - val_loss: 1.6300 - val_accuracy: 0.2720\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6216 - accuracy: 0.2840 - val_loss: 1.6230 - val_accuracy: 0.3020\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6225 - accuracy: 0.2880 - val_loss: 1.6247 - val_accuracy: 0.2720\n",
      "Epoch 16: early stopping\n",
      "Accuracy 0.27\n"
     ]
    }
   ],
   "source": [
    "#層の定義\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# モデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log = model.fit(train_x, train_y, epochs=100, batch_size=10, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                     min_delta=0, patience=10,\n",
    "                                                         verbose=1)],\n",
    "                validation_data=(valid_x, valid_y))\n",
    "\n",
    "loss,accuracy = model.evaluate(valid_x,valid_y,verbose = 0)\n",
    "print('Accuracy','{:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efc463-268a-42f2-9c0f-e9003a561506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
